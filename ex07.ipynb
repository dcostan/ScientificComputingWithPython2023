{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "1\\. **Spotting correlations**\n\nLoad the remote file:\n\n```bash\nhttps://www.dropbox.com/s/aamg1apjhclecka/regression_generated.csv\n```\n\nwith Pandas and create scatter plots with all possible combinations of the following features:\n    \n  + `features_1`\n  + `features_2`\n  + `features_3`\n  \nAre these features correlated? Please add a comment.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the file\ndata = pd.read_csv('regression_generated.csv')\n\n# Features to plot\nfeatures = ['features_1', 'features_2', 'features_3']\n\n# Create scatter plots\nfor i in range(len(features)):\n    for j in range(i+1, len(features)):\n        plt.scatter(data[features[i]], data[features[j]])\n        plt.xlabel(features[i])\n        plt.ylabel(features[j])\n        plt.show()\n\n# Check correlation between features\ncorrelation = data[features].corr()\nprint(correlation)\n\n# The correlation matrix indicates low correlation between the features",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "2\\. **Color-coded scatter plot**\n\nProduce a scatter plot from a dataset with two categories.\n\n* Write a function that generates a 2D dataset consisting of 2 categories. Each category should distribute as a 2D gaussian with a given mean and standard deviation. Set different values of the mean and standard deviation between the two samples.\n* Display the dataset in a scatter plot marking the two categories with different marker colors.\n\nAn example is given below:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from IPython.display import Image\nImage('images/two_categories_scatter_plot.png')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef generate_dataset(mean1, mean2, std1, std2, size):\n    # Generate data for category 1\n    category1 = np.random.multivariate_normal(mean1, std1, size)\n    \n    # Generate data for category 2\n    category2 = np.random.multivariate_normal(mean2, std2, size)\n    \n    # Combine the categories\n    dataset = np.concatenate((category1, category2))\n    \n    return dataset\n\n# Set the parameters for the dataset\nmean1 = [2, 3]  # Mean of category 1\nmean2 = [-1, -2]  # Mean of category 2\nstd1 = [[0.5, 0], [0, 0.5]]  # Standard deviation of category 1\nstd2 = [[1, 0], [0, 1]]  # Standard deviation of category 2\nsize = 100  # Size of each category\n\n# Generate the dataset\ndataset = generate_dataset(mean1, mean2, std1, std2, size)\n\n# Separate the categories\ncategory1 = dataset[:size]\ncategory2 = dataset[size:]\n\n# Plot the dataset\nplt.scatter(category1[:, 0], category1[:, 1], color='blue', label='Category 1')\nplt.scatter(category2[:, 0], category2[:, 1], color='red', label='Category 2')\n\n# Add labels and legend\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.legend()\n\n# Show the plot\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "3\\. **Profile plot**\n\nProduce a profile plot from a scatter plot.\n* Download the following pickle file:\n```bash\nwget https://www.dropbox.com/s/3uqleyc3wyz52tr/residuals_261.pkl -P data/\n```\n* Inspect the dataset, you'll find two variables (features)\n* Convert the content to a Pandas Dataframe\n* Clean the sample by selecting the entries (rows) with the absolute values of the variable \"residual\" smaller than 2\n* Plot a Seaborn `jointplot` of \"residuals\" versus \"distances\", and use seaborn to display a linear regression. \n\nComment on the correlation between these variables.\n\n* Create manually (without using seaborn) the profile histogram for the \"distance\" variable; choose an appropriate binning.\n* Obtain 3 numpy arrays:\n  * `x`, the array of bin centers of the profile histogram of the \"distance\" variable\n  * `y`, the mean values of the \"residuals\", estimated in slices (bins) of \"distance\"\n  * `err_y`, the standard deviation of the of the \"residuals\", estimated in slices (bins) of \"distance\"\n* Plot the profile plot on top of the scatter plot",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "4\\. **Kernel Density Estimate**\n\nProduce a KDE for a given distribution (by hand, not using seaborn):\n\n* Fill a numpy array `x` of length N (with $N=\\mathcal{O}(100)$) with a variable normally distributed, with a given mean and standard deviation\n* Fill an histogram in pyplot taking proper care of the aesthetic:\n   * use a meaningful number of bins\n   * set a proper y axis label\n   * set proper value of y axis major ticks labels (e.g. you want to display only integer labels)\n   * display the histograms as data points with errors (the error being the poisson uncertainty)\n* For every element of `x`, create a gaussian with the mean corresponding to the element value and the standard deviation as a parameter that can be tuned. The standard deviation default value should be:\n$$ 1.06 * x.std() * x.size ^{-\\frac{1}{5}} $$\nyou can use the scipy function `stats.norm()` for that.\n* In a separate plot (to be placed beside the original histogram), plot all the gaussian functions so obtained\n* Sum (with `np.sum()`) all the gaussian functions and normalize the result such that the integral matches the integral of the original histogram. For that you could use the `scipy.integrate.trapz()` method. Superimpose the normalized sum of all gaussians to the first histogram.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}